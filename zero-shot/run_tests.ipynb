{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from pprint import pprint\n",
    "from datasets import load_dataset, DatasetDict\n",
    "import tiktoken\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_tokens(prompt, model=\"gpt-4o-mini\"):\n",
    "    \"\"\"\n",
    "    Estimate the number of tokens in a given prompt for a specific model.\n",
    "    :param prompt: The text prompt to estimate tokens for.\n",
    "    :param model: The model name (e.g., \"gpt-4\", \"gpt-3.5-turbo\").\n",
    "    :return: The estimated token count.\n",
    "    \"\"\"\n",
    "    # Load the tokenizer for the specified model\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    tokens = encoding.encode(prompt)\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(filename, data):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "    f.close()\n",
    "    \n",
    "def read_file(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def collect_labels(all_predictions):\n",
    "    print(len(all_predictions))\n",
    "    output_labels = []\n",
    "    for i, message in enumerate(all_predictions):\n",
    "        # print(message)\n",
    "        output_labels.append(int(message.strip().split('Classification: ')[1]))\n",
    "    return output_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_clauses_batch(clauses, system_prompt, batch_size=10, model=\"gpt-4o-mini\", test=False):\n",
    "    all_predictions = []\n",
    "    invalid_batch_nums = []\n",
    "    for i in range(0, len(clauses), batch_size):\n",
    "        batch_clauses = clauses[i: i + batch_size]\n",
    "        user_prompt = \"Classify the following clauses:\\n\" + \"\\n\".join(\n",
    "            [f\"{j+1}. {clause}\" for j, clause in enumerate(batch_clauses)]\n",
    "        )\n",
    "        full_prompt = system_prompt + \"\\n\" + user_prompt\n",
    "        token_count = estimate_tokens(full_prompt, model=model)\n",
    "        print(\n",
    "            f\"Estimated token count for batch {i // batch_size + 1}: {token_count}\")\n",
    "\n",
    "        try:\n",
    "            response = openai.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                temperature=0,  # For consistent results\n",
    "            )\n",
    "            # response = openai.chat.completions.create(\n",
    "            #     model=model,\n",
    "            #     messages=[\n",
    "            #         {\n",
    "            #             \"role\": \"user\",\n",
    "            #             \"content\": full_prompt\n",
    "            #         }\n",
    "            #     ]\n",
    "            # )\n",
    "            # Extract classifications from the response\n",
    "            batch_predictions = []\n",
    "            for choice in response.choices:\n",
    "                message_content = choice.message.content\n",
    "                batch_predictions.extend(message_content.strip().split(\"\\n\"))\n",
    "\n",
    "            \n",
    "            # Verify the number of classifications matches the batch size\n",
    "            if len(batch_predictions) != len(batch_clauses):\n",
    "                invalid_batch_nums.append(i // batch_size + 1)\n",
    "                print(\n",
    "                    f\"WARNING: Mismatch in batch size for Batch {i // batch_size + 1}!\")\n",
    "                print(\n",
    "                    f\"Expected {len(batch_clauses)} classifications, but got {len(batch_predictions)}.\")\n",
    "\n",
    "            # Append verified predictions to the final list\n",
    "            all_predictions.extend(batch_predictions)\n",
    "            print(\n",
    "                f\"Batch {i // batch_size + 1} processed successfully with {len(batch_predictions)} classifications.\")\n",
    "            if test:\n",
    "                return all_predictions, invalid_batch_nums\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch {i // batch_size + 1}: {e}\")\n",
    "            return all_predictions, invalid_batch_nums\n",
    "    return all_predictions, invalid_batch_nums\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(ground_truth, predictions):\n",
    "    \"\"\"\n",
    "    Evaluates the predictions against ground truth labels and calculates metrics.\n",
    "\n",
    "    Args:\n",
    "      ground_truth: A list of ground truth labels (0 for Fair, 1 for Unfair).\n",
    "      predictions: A list of predicted labels (0 for Fair, 1 for Unfair).\n",
    "\n",
    "    Returns:\n",
    "      A dictionary containing the calculated metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    accuracy = accuracy_score(ground_truth, predictions)\n",
    "    precision = precision_score(ground_truth, predictions)\n",
    "    recall = recall_score(ground_truth, predictions)\n",
    "    f1 = f1_score(ground_truth, predictions)\n",
    "\n",
    "    metrics = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_claudette_tos_dataset():\n",
    "    dataset = load_dataset(\"LawInformedAI/claudette_tos\")['train']\n",
    "    dataset = dataset.class_encode_column('label')\n",
    "    split1 = dataset.train_test_split(\n",
    "        test_size=0.2,\n",
    "        stratify_by_column='label',\n",
    "        seed=42\n",
    "    )\n",
    "    split2 = split1['test'].train_test_split(\n",
    "        test_size=0.5,\n",
    "        stratify_by_column='label',\n",
    "        seed=42\n",
    "    )\n",
    "    # Combine splits\n",
    "    final_splits = DatasetDict({\n",
    "        'train': split1['train'],\n",
    "        'validation': split2['train'],\n",
    "        'test': split2['test']\n",
    "    })\n",
    "\n",
    "    return final_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a legal expert in consumer rights and contract law. Your task is to classify clauses from Terms of Service (ToS) \n",
    "documents as either '0' (Fair) or '1' (Unfair).\n",
    "\n",
    "A clause is '1' (Unfair) if it:\n",
    "1. Limits or excludes the provider's liability for damages.\n",
    "2. Allows the provider to terminate services or the contract unilaterally.\n",
    "3. Allows the provider to change contract terms unilaterally.\n",
    "4. Grants the provider rights to remove content without reason or notice.\n",
    "5. Binds users to terms simply by using the service, without explicit agreement.\n",
    "6. Specifies governing law favoring the provider over the user's country.\n",
    "7. Forces dispute resolution in a jurisdiction not favorable to the user.\n",
    "8. Forces arbitration restricting the user's legal rights.\n",
    "9. Imposes unreasonable restrictions or obligations on users.\n",
    "10. Significantly limits users' rights or remedies.\n",
    "11. Creates an imbalance of power favoring the service provider.\n",
    "12. Uses vague or ambiguous language that could be exploited.\n",
    "13. Violates established legal principles or consumer protection laws.\n",
    "\n",
    "Classify ONLY the clauses provided in the user prompt. Provide ONLY the classification ('Classification: 0' or 'Classification: 1') \n",
    "for each clause, line by line, in the same order as the input. Do not add extra lines, blank lines, or explanations.\n",
    "Example:\n",
    "Classification: 0\n",
    "Classification: 1\n",
    "\"\"\"\n",
    "\n",
    "final_splits = load_claudette_tos_dataset()\n",
    "\n",
    "validation_clauses = final_splits['validation']['text']\n",
    "validation_labels = final_splits['validation']['label']\n",
    "\n",
    "# train_clauses = final_splits['train']['text']\n",
    "# train_labels = final_splits['validation']['label']\n",
    "\n",
    "test_clauses = final_splits['test']['text']\n",
    "test_labels = final_splits['test']['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.7640807651434643,\n",
       " 'Precision': 0.30618892508143325,\n",
       " 'Recall': 0.912621359223301,\n",
       " 'F1-Score': 0.4585365853658537}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = openai.models.retrieve(\"o1-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated token count for batch 1: 535\n",
      "Batch 1 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 2: 441\n",
      "Batch 2 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 3: 445\n",
      "Batch 3 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 4: 596\n",
      "Batch 4 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 5: 486\n",
      "Batch 5 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 6: 511\n",
      "Batch 6 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 7: 456\n",
      "Batch 7 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 8: 521\n",
      "Batch 8 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 9: 627\n",
      "Batch 9 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 10: 437\n",
      "Batch 10 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 11: 426\n",
      "Batch 11 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 12: 484\n",
      "Batch 12 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 13: 407\n",
      "Batch 13 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 14: 464\n",
      "Batch 14 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 15: 447\n",
      "Batch 15 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 16: 438\n",
      "Batch 16 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 17: 475\n",
      "Batch 17 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 18: 485\n",
      "Batch 18 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 19: 499\n",
      "Batch 19 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 20: 421\n",
      "Batch 20 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 21: 431\n",
      "Batch 21 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 22: 797\n",
      "Batch 22 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 23: 439\n",
      "Batch 23 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 24: 448\n",
      "Batch 24 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 25: 468\n",
      "Batch 25 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 26: 494\n",
      "Batch 26 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 27: 450\n",
      "Batch 27 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 28: 490\n",
      "Batch 28 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 29: 434\n",
      "Batch 29 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 30: 434\n",
      "Batch 30 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 31: 458\n",
      "Batch 31 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 32: 519\n",
      "Batch 32 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 33: 428\n",
      "Batch 33 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 34: 481\n",
      "Batch 34 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 35: 553\n",
      "Batch 35 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 36: 543\n",
      "Batch 36 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 37: 573\n",
      "Batch 37 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 38: 461\n",
      "Batch 38 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 39: 489\n",
      "Batch 39 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 40: 450\n",
      "Batch 40 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 41: 438\n",
      "Batch 41 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 42: 471\n",
      "Batch 42 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 43: 623\n",
      "Batch 43 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 44: 381\n",
      "Batch 44 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 45: 448\n",
      "Batch 45 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 46: 506\n",
      "Batch 46 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 47: 420\n",
      "Batch 47 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 48: 824\n",
      "Batch 48 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 49: 403\n",
      "Batch 49 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 50: 521\n",
      "Batch 50 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 51: 397\n",
      "Batch 51 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 52: 454\n",
      "Batch 52 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 53: 457\n",
      "Batch 53 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 54: 534\n",
      "Batch 54 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 55: 424\n",
      "Batch 55 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 56: 525\n",
      "Batch 56 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 57: 491\n",
      "Batch 57 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 58: 531\n",
      "Batch 58 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 59: 470\n",
      "Batch 59 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 60: 463\n",
      "Batch 60 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 61: 591\n",
      "Batch 61 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 62: 439\n",
      "Batch 62 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 63: 426\n",
      "Batch 63 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 64: 416\n",
      "Batch 64 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 65: 526\n",
      "Batch 65 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 66: 504\n",
      "Batch 66 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 67: 515\n",
      "Batch 67 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 68: 472\n",
      "Batch 68 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 69: 397\n",
      "Batch 69 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 70: 477\n",
      "Batch 70 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 71: 585\n",
      "Batch 71 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 72: 494\n",
      "Batch 72 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 73: 594\n",
      "Batch 73 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 74: 478\n",
      "Batch 74 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 75: 480\n",
      "Batch 75 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 76: 561\n",
      "Batch 76 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 77: 516\n",
      "Batch 77 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 78: 431\n",
      "Batch 78 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 79: 504\n",
      "Batch 79 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 80: 537\n",
      "Batch 80 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 81: 460\n",
      "Batch 81 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 82: 459\n",
      "Batch 82 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 83: 479\n",
      "Batch 83 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 84: 445\n",
      "Batch 84 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 85: 512\n",
      "Batch 85 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 86: 578\n",
      "Batch 86 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 87: 471\n",
      "Batch 87 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 88: 437\n",
      "Batch 88 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 89: 711\n",
      "Batch 89 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 90: 596\n",
      "Batch 90 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 91: 558\n",
      "Batch 91 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 92: 569\n",
      "Batch 92 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 93: 400\n",
      "Batch 93 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 94: 430\n",
      "Batch 94 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 95: 576\n",
      "Batch 95 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 96: 447\n",
      "Batch 96 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 97: 562\n",
      "Batch 97 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 98: 568\n",
      "Batch 98 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 99: 405\n",
      "Batch 99 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 100: 460\n",
      "Batch 100 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 101: 582\n",
      "Batch 101 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 102: 434\n",
      "Batch 102 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 103: 530\n",
      "Batch 103 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 104: 545\n",
      "Batch 104 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 105: 454\n",
      "Batch 105 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 106: 558\n",
      "Batch 106 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 107: 451\n",
      "Batch 107 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 108: 508\n",
      "Batch 108 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 109: 481\n",
      "Batch 109 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 110: 493\n",
      "Batch 110 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 111: 631\n",
      "Batch 111 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 112: 473\n",
      "Batch 112 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 113: 432\n",
      "Batch 113 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 114: 401\n",
      "Batch 114 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 115: 439\n",
      "Batch 115 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 116: 441\n",
      "Batch 116 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 117: 533\n",
      "Batch 117 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 118: 475\n",
      "Batch 118 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 119: 515\n",
      "Batch 119 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 120: 493\n",
      "Batch 120 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 121: 548\n",
      "Batch 121 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 122: 546\n",
      "Batch 122 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 123: 486\n",
      "Batch 123 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 124: 528\n",
      "Batch 124 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 125: 454\n",
      "Batch 125 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 126: 465\n",
      "Batch 126 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 127: 445\n",
      "Batch 127 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 128: 463\n",
      "Batch 128 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 129: 473\n",
      "Batch 129 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 130: 635\n",
      "Batch 130 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 131: 492\n",
      "Batch 131 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 132: 436\n",
      "Batch 132 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 133: 520\n",
      "Batch 133 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 134: 467\n",
      "Batch 134 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 135: 504\n",
      "Batch 135 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 136: 404\n",
      "Batch 136 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 137: 524\n",
      "Batch 137 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 138: 425\n",
      "Batch 138 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 139: 507\n",
      "Batch 139 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 140: 458\n",
      "Batch 140 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 141: 481\n",
      "Batch 141 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 142: 513\n",
      "Batch 142 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 143: 522\n",
      "Batch 143 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 144: 450\n",
      "Batch 144 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 145: 416\n",
      "Batch 145 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 146: 522\n",
      "Batch 146 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 147: 399\n",
      "Batch 147 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 148: 516\n",
      "Batch 148 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 149: 459\n",
      "Batch 149 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 150: 439\n",
      "Batch 150 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 151: 704\n",
      "Batch 151 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 152: 699\n",
      "Batch 152 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 153: 461\n",
      "Batch 153 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 154: 472\n",
      "Batch 154 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 155: 482\n",
      "Batch 155 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 156: 526\n",
      "Batch 156 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 157: 569\n",
      "Batch 157 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 158: 469\n",
      "Batch 158 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 159: 537\n",
      "Batch 159 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 160: 650\n",
      "Batch 160 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 161: 496\n",
      "Batch 161 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 162: 442\n",
      "Batch 162 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 163: 493\n",
      "Batch 163 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 164: 530\n",
      "Batch 164 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 165: 404\n",
      "Batch 165 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 166: 617\n",
      "Batch 166 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 167: 523\n",
      "Batch 167 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 168: 419\n",
      "Batch 168 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 169: 470\n",
      "Batch 169 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 170: 693\n",
      "Batch 170 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 171: 439\n",
      "Batch 171 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 172: 567\n",
      "Batch 172 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 173: 433\n",
      "Batch 173 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 174: 500\n",
      "Batch 174 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 175: 550\n",
      "Batch 175 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 176: 431\n",
      "Batch 176 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 177: 514\n",
      "Batch 177 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 178: 595\n",
      "Batch 178 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 179: 462\n",
      "Batch 179 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 180: 386\n",
      "Batch 180 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 181: 442\n",
      "Batch 181 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 182: 481\n",
      "Batch 182 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 183: 439\n",
      "Batch 183 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 184: 488\n",
      "Batch 184 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 185: 496\n",
      "Batch 185 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 186: 537\n",
      "Batch 186 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 187: 569\n",
      "Batch 187 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 188: 427\n",
      "Batch 188 processed successfully with 5 classifications.\n",
      "Estimated token count for batch 189: 436\n",
      "Batch 189 processed successfully with 2 classifications.\n"
     ]
    }
   ],
   "source": [
    "test_predictions, invalid_batch_nums = classify_clauses_batch(\n",
    "    test_clauses, system_prompt, batch_size=5, model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_predictions.remove(\"```\")\n",
    "# test_predictions.count(\"```\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[73]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_labels[-5:]\n",
    "invalid_batch_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "942"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "942\n"
     ]
    }
   ],
   "source": [
    "test_predictions_labels = collect_labels(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "942"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_predictions_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "942"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = evaluate_predictions(test_labels, test_predictions_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.7802547770700637,\n",
       " 'Precision': 0.32068965517241377,\n",
       " 'Recall': 0.9029126213592233,\n",
       " 'F1-Score': 0.4732824427480916}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gpt-4\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.7526539278131635,\n",
       " 'Precision': 0.2929936305732484,\n",
       " 'Recall': 0.8932038834951457,\n",
       " 'F1-Score': 0.4412470023980815}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gpt4o-mini\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.8089171974522293,\n",
       " 'Precision': 0.35361216730038025,\n",
       " 'Recall': 0.9029126213592233,\n",
       " 'F1-Score': 0.5081967213114754}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#o4-mini results\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.856687898089172,\n",
       " 'Precision': 0.42727272727272725,\n",
       " 'Recall': 0.912621359223301,\n",
       " 'F1-Score': 0.5820433436532507}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# o3-mini results\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.7452229299363057,\n",
       " 'Precision': 0.290519877675841,\n",
       " 'Recall': 0.9223300970873787,\n",
       " 'F1-Score': 0.4418604651162791}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# o1-mini results\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.7866242038216561,\n",
       " 'Precision': 0.32867132867132864,\n",
       " 'Recall': 0.912621359223301,\n",
       " 'F1-Score': 0.4832904884318766}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gpt-4 Results\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.7505307855626328,\n",
       " 'Precision': 0.2962962962962963,\n",
       " 'Recall': 0.9320388349514563,\n",
       " 'F1-Score': 0.4496487119437939}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4o-mini results\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(\"test-o4mini-5-improved.pkl\", test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.7346072186836518,\n",
       " 'Precision': 0.25418060200668896,\n",
       " 'Recall': 0.7378640776699029,\n",
       " 'F1-Score': 0.3781094527363184}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(\"test-gpt4o-5-improved.pkl\", test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.7346072186836518,\n",
       " 'Precision': 0.25418060200668896,\n",
       " 'Recall': 0.7378640776699029,\n",
       " 'F1-Score': 0.3781094527363184}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_file(\"test-gpt4o-batch-10.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.7452229299363057,\n",
       " 'Precision': 0.290519877675841,\n",
       " 'Recall': 0.9223300970873787,\n",
       " 'F1-Score': 0.4418604651162791}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_file(\"test-o1mini-10-improved.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legal-anomaly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

=== Starting job on gypsum-gpu002 at Thu May  8 11:46:58 PM UTC 2025 ===
Python version: Python 3.11.7
Torch version: 2.7.0+cu126
Transformers version: 4.51.3
Running fine-tuning...
Transformers version: 4.51.3
TrainingArguments path: transformers.training_args
Training dataset size: 1920
Validation dataset size: 80
Loading tokenizer from Equall/Saul-7B-Base...
Loading Equall/Saul-7B-Base model with 4-bit quantization...
trainable params: 13,631,488 || all params: 7,255,363,584 || trainable%: 0.1879
Starting training...
Starting training...
Resuming from checkpoint: /home/njuttu_umass_edu/685/ZeroShotAnomolyDetection-1/SaulLM:7B/saul-7b-anomaly/checkpoint-40
{'loss': 0.5925, 'grad_norm': 1.5484906435012817, 'learning_rate': 9.166666666666667e-05, 'epoch': 0.09375}
{'loss': 0.5763, 'grad_norm': 2.0048646926879883, 'learning_rate': 9.062500000000001e-05, 'epoch': 0.10416666666666667}
{'loss': 0.5842, 'grad_norm': 1.6788020133972168, 'learning_rate': 8.958333333333335e-05, 'epoch': 0.11458333333333333}
{'loss': 0.4824, 'grad_norm': 1.55182683467865, 'learning_rate': 8.854166666666667e-05, 'epoch': 0.125}
{'loss': 0.5654, 'grad_norm': 1.9770519733428955, 'learning_rate': 8.75e-05, 'epoch': 0.13541666666666666}
{'loss': 0.4595, 'grad_norm': 1.7350666522979736, 'learning_rate': 8.645833333333334e-05, 'epoch': 0.14583333333333334}
{'loss': 0.508, 'grad_norm': 2.0380094051361084, 'learning_rate': 8.541666666666666e-05, 'epoch': 0.15625}
{'loss': 0.5381, 'grad_norm': 2.3198201656341553, 'learning_rate': 8.4375e-05, 'epoch': 0.16666666666666666}
{'loss': 0.7759, 'grad_norm': 1.7353607416152954, 'learning_rate': 8.333333333333334e-05, 'epoch': 0.17708333333333334}
{'loss': 0.6768, 'grad_norm': 2.319894313812256, 'learning_rate': 8.229166666666667e-05, 'epoch': 0.1875}
{'loss': 0.6017, 'grad_norm': 1.7079750299453735, 'learning_rate': 8.125000000000001e-05, 'epoch': 0.19791666666666666}
{'loss': 0.6482, 'grad_norm': 1.7299320697784424, 'learning_rate': 8.020833333333334e-05, 'epoch': 0.20833333333333334}
{'loss': 0.6674, 'grad_norm': 2.8563833236694336, 'learning_rate': 7.916666666666666e-05, 'epoch': 0.21875}
{'loss': 0.6874, 'grad_norm': 1.7114313840866089, 'learning_rate': 7.8125e-05, 'epoch': 0.22916666666666666}
{'loss': 0.5941, 'grad_norm': 2.7171554565429688, 'learning_rate': 7.708333333333334e-05, 'epoch': 0.23958333333333334}
{'loss': 0.5568, 'grad_norm': 1.9113612174987793, 'learning_rate': 7.604166666666667e-05, 'epoch': 0.25}
{'loss': 0.6327, 'grad_norm': 1.3655831813812256, 'learning_rate': 7.500000000000001e-05, 'epoch': 0.2604166666666667}
{'loss': 0.5311, 'grad_norm': 2.308332681655884, 'learning_rate': 7.395833333333335e-05, 'epoch': 0.2708333333333333}
{'loss': 0.6605, 'grad_norm': 2.0216012001037598, 'learning_rate': 7.291666666666667e-05, 'epoch': 0.28125}
{'loss': 0.8038, 'grad_norm': 5.717541694641113, 'learning_rate': 7.1875e-05, 'epoch': 0.2916666666666667}
{'loss': 0.4588, 'grad_norm': 1.3970487117767334, 'learning_rate': 7.083333333333334e-05, 'epoch': 0.3020833333333333}
{'loss': 0.4129, 'grad_norm': 1.359601378440857, 'learning_rate': 6.979166666666666e-05, 'epoch': 0.3125}
{'loss': 0.6036, 'grad_norm': 3.3316895961761475, 'learning_rate': 6.875e-05, 'epoch': 0.3229166666666667}
{'loss': 0.4717, 'grad_norm': 1.239990234375, 'learning_rate': 6.770833333333334e-05, 'epoch': 0.3333333333333333}
{'loss': 0.4344, 'grad_norm': 1.9890474081039429, 'learning_rate': 6.666666666666667e-05, 'epoch': 0.34375}
{'loss': 0.5723, 'grad_norm': 2.0331695079803467, 'learning_rate': 6.562500000000001e-05, 'epoch': 0.3541666666666667}
{'loss': 0.5016, 'grad_norm': 1.9159209728240967, 'learning_rate': 6.458333333333334e-05, 'epoch': 0.3645833333333333}
{'loss': 0.6409, 'grad_norm': 2.3312036991119385, 'learning_rate': 6.354166666666666e-05, 'epoch': 0.375}
{'loss': 0.6788, 'grad_norm': 1.4037119150161743, 'learning_rate': 6.25e-05, 'epoch': 0.3854166666666667}
{'loss': 0.5766, 'grad_norm': 1.9282807111740112, 'learning_rate': 6.145833333333334e-05, 'epoch': 0.3958333333333333}
{'loss': 0.5671, 'grad_norm': 1.899720549583435, 'learning_rate': 6.041666666666667e-05, 'epoch': 0.40625}
{'loss': 0.5943, 'grad_norm': 2.275294542312622, 'learning_rate': 5.9375e-05, 'epoch': 0.4166666666666667}
{'loss': 0.3782, 'grad_norm': 1.6763856410980225, 'learning_rate': 5.833333333333334e-05, 'epoch': 0.4270833333333333}
{'loss': 0.5143, 'grad_norm': 1.367446780204773, 'learning_rate': 5.7291666666666666e-05, 'epoch': 0.4375}
{'loss': 0.5797, 'grad_norm': 1.7246800661087036, 'learning_rate': 5.6250000000000005e-05, 'epoch': 0.4479166666666667}
{'loss': 0.4433, 'grad_norm': 0.993841826915741, 'learning_rate': 5.520833333333334e-05, 'epoch': 0.4583333333333333}
{'loss': 0.4559, 'grad_norm': 1.2419642210006714, 'learning_rate': 5.4166666666666664e-05, 'epoch': 0.46875}
{'loss': 0.6263, 'grad_norm': 2.0036635398864746, 'learning_rate': 5.3125000000000004e-05, 'epoch': 0.4791666666666667}
{'loss': 0.5379, 'grad_norm': 1.954087495803833, 'learning_rate': 5.208333333333334e-05, 'epoch': 0.4895833333333333}
{'loss': 0.4533, 'grad_norm': 1.195410132408142, 'learning_rate': 5.104166666666666e-05, 'epoch': 0.5}
{'loss': 0.5316, 'grad_norm': 2.510701894760132, 'learning_rate': 5e-05, 'epoch': 0.5104166666666666}
{'loss': 0.4809, 'grad_norm': 2.1682515144348145, 'learning_rate': 4.8958333333333335e-05, 'epoch': 0.5208333333333334}
{'loss': 0.493, 'grad_norm': 2.139457941055298, 'learning_rate': 4.791666666666667e-05, 'epoch': 0.53125}
{'loss': 0.4859, 'grad_norm': 1.703249454498291, 'learning_rate': 4.6875e-05, 'epoch': 0.5416666666666666}
{'loss': 0.4614, 'grad_norm': 1.5331956148147583, 'learning_rate': 4.5833333333333334e-05, 'epoch': 0.5520833333333334}
{'loss': 0.4554, 'grad_norm': 2.670968770980835, 'learning_rate': 4.4791666666666673e-05, 'epoch': 0.5625}
{'loss': 0.4894, 'grad_norm': 1.5641980171203613, 'learning_rate': 4.375e-05, 'epoch': 0.5729166666666666}
{'loss': 0.5677, 'grad_norm': 1.6668280363082886, 'learning_rate': 4.270833333333333e-05, 'epoch': 0.5833333333333334}
{'loss': 0.3974, 'grad_norm': 1.2540502548217773, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.59375}
{'loss': 0.5016, 'grad_norm': 1.777604341506958, 'learning_rate': 4.0625000000000005e-05, 'epoch': 0.6041666666666666}
{'loss': 0.5203, 'grad_norm': 1.7177051305770874, 'learning_rate': 3.958333333333333e-05, 'epoch': 0.6145833333333334}
{'loss': 0.5331, 'grad_norm': 1.5166646242141724, 'learning_rate': 3.854166666666667e-05, 'epoch': 0.625}
{'loss': 0.5185, 'grad_norm': 1.9432528018951416, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.6354166666666666}
{'loss': 0.4949, 'grad_norm': 1.7928471565246582, 'learning_rate': 3.6458333333333336e-05, 'epoch': 0.6458333333333334}
{'loss': 0.5944, 'grad_norm': 1.5866245031356812, 'learning_rate': 3.541666666666667e-05, 'epoch': 0.65625}
{'loss': 0.4304, 'grad_norm': 1.9292079210281372, 'learning_rate': 3.4375e-05, 'epoch': 0.6666666666666666}
{'loss': 0.496, 'grad_norm': 2.36454701423645, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.6770833333333334}
{'loss': 0.5021, 'grad_norm': 1.500688910484314, 'learning_rate': 3.229166666666667e-05, 'epoch': 0.6875}
{'loss': 0.5116, 'grad_norm': 3.0384695529937744, 'learning_rate': 3.125e-05, 'epoch': 0.6979166666666666}
{'loss': 0.4594, 'grad_norm': 1.8359262943267822, 'learning_rate': 3.0208333333333334e-05, 'epoch': 0.7083333333333334}
{'loss': 0.4099, 'grad_norm': 1.6584618091583252, 'learning_rate': 2.916666666666667e-05, 'epoch': 0.71875}
{'loss': 0.4762, 'grad_norm': 1.6165995597839355, 'learning_rate': 2.8125000000000003e-05, 'epoch': 0.7291666666666666}
{'loss': 0.4078, 'grad_norm': 1.5325968265533447, 'learning_rate': 2.7083333333333332e-05, 'epoch': 0.7395833333333334}
{'loss': 0.6383, 'grad_norm': 1.2517361640930176, 'learning_rate': 2.604166666666667e-05, 'epoch': 0.75}
{'loss': 0.4122, 'grad_norm': 3.199876546859741, 'learning_rate': 2.5e-05, 'epoch': 0.7604166666666666}
{'loss': 0.5212, 'grad_norm': 2.2731130123138428, 'learning_rate': 2.3958333333333334e-05, 'epoch': 0.7708333333333334}
{'loss': 0.4134, 'grad_norm': 1.1191118955612183, 'learning_rate': 2.2916666666666667e-05, 'epoch': 0.78125}
{'loss': 0.4287, 'grad_norm': 1.3825488090515137, 'learning_rate': 2.1875e-05, 'epoch': 0.7916666666666666}
{'loss': 0.5211, 'grad_norm': 1.1381001472473145, 'learning_rate': 2.0833333333333336e-05, 'epoch': 0.8020833333333334}
{'loss': 0.746, 'grad_norm': 1.6773737668991089, 'learning_rate': 1.9791666666666665e-05, 'epoch': 0.8125}
{'loss': 0.3597, 'grad_norm': 1.2968016862869263, 'learning_rate': 1.8750000000000002e-05, 'epoch': 0.8229166666666666}
{'loss': 0.4377, 'grad_norm': 2.3977530002593994, 'learning_rate': 1.7708333333333335e-05, 'epoch': 0.8333333333333334}
{'loss': 0.4244, 'grad_norm': 2.00659441947937, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.84375}
{'loss': 0.4222, 'grad_norm': 1.019507646560669, 'learning_rate': 1.5625e-05, 'epoch': 0.8541666666666666}
{'loss': 0.452, 'grad_norm': 1.7547074556350708, 'learning_rate': 1.4583333333333335e-05, 'epoch': 0.8645833333333334}
{'loss': 0.5668, 'grad_norm': 1.686480164527893, 'learning_rate': 1.3541666666666666e-05, 'epoch': 0.875}
{'loss': 0.5174, 'grad_norm': 1.6264175176620483, 'learning_rate': 1.25e-05, 'epoch': 0.8854166666666666}
{'loss': 0.6968, 'grad_norm': 1.7326823472976685, 'learning_rate': 1.1458333333333333e-05, 'epoch': 0.8958333333333334}
{'loss': 0.4094, 'grad_norm': 1.3064604997634888, 'learning_rate': 1.0416666666666668e-05, 'epoch': 0.90625}
{'loss': 0.4117, 'grad_norm': 1.7034735679626465, 'learning_rate': 9.375000000000001e-06, 'epoch': 0.9166666666666666}
{'loss': 0.4522, 'grad_norm': 1.4660934209823608, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.9270833333333334}
{'loss': 0.485, 'grad_norm': 1.4881560802459717, 'learning_rate': 7.2916666666666674e-06, 'epoch': 0.9375}
{'loss': 0.4168, 'grad_norm': 2.2322885990142822, 'learning_rate': 6.25e-06, 'epoch': 0.9479166666666666}
{'loss': 0.5265, 'grad_norm': 1.9189465045928955, 'learning_rate': 5.208333333333334e-06, 'epoch': 0.9583333333333334}
{'loss': 0.4111, 'grad_norm': 1.2470710277557373, 'learning_rate': 4.166666666666667e-06, 'epoch': 0.96875}
{'loss': 0.4, 'grad_norm': 1.309362769126892, 'learning_rate': 3.125e-06, 'epoch': 0.9791666666666666}
{'loss': 0.5153, 'grad_norm': 1.7036802768707275, 'learning_rate': 2.0833333333333334e-06, 'epoch': 0.9895833333333334}
{'loss': 0.5904, 'grad_norm': 1.5588843822479248, 'learning_rate': 1.0416666666666667e-06, 'epoch': 1.0}
{'train_runtime': 19184.4006, 'train_samples_per_second': 0.1, 'train_steps_per_second': 0.025, 'train_loss': 0.47957858443260193, 'epoch': 1.0}
Saving model...
Saving model...
=== Job finished at Fri May  9 05:07:39 AM UTC 2025 ===
